{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing libraries\n",
    "\n",
    "import re\n",
    "import pandas as pd\n",
    "import pyttsx3\n",
    "from sklearn import preprocessing\n",
    "from sklearn.tree import DecisionTreeClassifier,_tree\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.svm import SVC\n",
    "import csv\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\", category=DeprecationWarning)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Carga los dataset de testeo y de training y le saca la ultima columna que es la que tiene los tags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['itching', 'skin_rash', 'nodal_skin_eruptions', 'continuous_sneezing',\n",
       "       'shivering', 'chills', 'joint_pain', 'stomach_pain', 'acidity',\n",
       "       'ulcers_on_tongue',\n",
       "       ...\n",
       "       'pus_filled_pimples', 'blackheads', 'scurring', 'skin_peeling',\n",
       "       'silver_like_dusting', 'small_dents_in_nails', 'inflammatory_nails',\n",
       "       'blister', 'red_sore_around_nose', 'yellow_crust_ooze'],\n",
       "      dtype='object', length=132)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training = pd.read_csv('Data/Training.csv')\n",
    "testing= pd.read_csv('Data/Testing.csv')\n",
    "cols= training.columns\n",
    "cols= cols[:-1]\n",
    "cols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = training[cols] # brings all the 1's and 0's\n",
    "y = training['prognosis'] # gives all the possible diseases\n",
    "y1= y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "reduce el dataset con los datos que estan en 1 para saber cual es la enfermedad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "reduced_data = training.groupby(training['prognosis']).max() # max?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Mapea las enfermedades a numeros.\n",
    "Splitea el dataset, usando un seed\n",
    "Transforma la calomuna de prognosis del testing csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#mapping strings to numbers\n",
    "le = preprocessing.LabelEncoder()\n",
    "le.fit(y)\n",
    "y = le.transform(y)\n",
    "\n",
    "\n",
    "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.33, random_state=42)\n",
    "testx    = testing[cols]\n",
    "testy    = testing['prognosis']  \n",
    "testy    = le.transform(testy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Prueba el modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9735274524649128\n"
     ]
    }
   ],
   "source": [
    "# DecisionTreeClassifier Model\n",
    "\n",
    "clf1  = DecisionTreeClassifier()\n",
    "clf = clf1.fit(x_train,y_train)\n",
    "# print(clf.score(x_train,y_train))\n",
    "# print (\"cross result========\")\n",
    "scores = cross_val_score(clf, x_test, y_test, cv=3)\n",
    "# print (scores)\n",
    "print (scores.mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hace lo mismo con el svc model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "for svm: \n",
      "1.0\n"
     ]
    }
   ],
   "source": [
    "# SVC Model\n",
    "\n",
    "model=SVC()\n",
    "model.fit(x_train,y_train)\n",
    "print(\"for svm: \")\n",
    "print(model.score(x_test,y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "obtiene las caracteristicas del modelo y las ordena por su importnacia."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "132\n",
      "132\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([ 97,  52,  93,  79, 105, 128,  72, 118, 131,   2,  86, 101,  19,\n",
       "       117, 119,  95, 109,  33,  41,  63,  98,  36,  77,  83,  11,   4,\n",
       "       100,  91,   0, 108, 111,  22,  34, 106,   7, 113, 122,  61,  26,\n",
       "        27, 102,  35,   3,  78, 123,  29,  28,  12,   6,  48,  10,  87,\n",
       "        39,  56, 130,  84,  25,  14,  89,  24,  43,   1,  49,  59,  30,\n",
       "        85,  68,  32, 124,  40, 129,  38, 127,  37,   5,   8,   9,  21,\n",
       "        23,  31, 126,  13,  15,  16,  17,  18, 125,  42,  20,  51,  44,\n",
       "       112,  74,  75,  76, 115, 114,  80,  81,  82,  88,  45,  90,  92,\n",
       "       110,  94,  96, 107,  99, 104,  73, 116,  71,  70,  46,  47,  50,\n",
       "       103, 121,  53,  54,  55,  57,  58,  60,  62, 120,  64,  66,  67,\n",
       "        69,  65])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "importances = clf.feature_importances_\n",
    "indices = np.argsort(importances)[::-1]\n",
    "features = cols\n",
    "print(len(indices)) # Indices and Cols (symptoms asked) have the same length\n",
    "print(len(cols)) # I don't know if the order is mantained\n",
    "indices # I understand that this gives the importance of each feature"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Le da un indice al sintoma para acceder desde el sintoma"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "severityDictionary=dict()\n",
    "description_list = dict()\n",
    "precautionDictionary=dict()\n",
    "\n",
    "symptoms_dict = {}\n",
    "\n",
    "# Gives a dict like {\"symptom1\": 0, \"symptom2\": 1, ..., \"symptomN\": n-1}\n",
    "for index, symptom in enumerate(x):\n",
    "       symptoms_dict[symptom] = index\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_condition(exp,days):\n",
    "    sum=0\n",
    "    for item in exp:\n",
    "         sum=sum+severityDictionary[item]\n",
    "    if((sum*days)/(len(exp)+1)>13):\n",
    "        print(\"You should take the consultation from doctor. \")\n",
    "    else:\n",
    "        print(\"It might not be that bad but you should take precautions.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This function fills the description_list dict. with the data in symptom_Description.csv. It gives a \"<Disease, Description>\" dict.\n",
    "def getDescription():\n",
    "    global description_list\n",
    "    with open('MasterData/symptom_Description.csv') as csv_file:\n",
    "        csv_reader = csv.reader(csv_file, delimiter=',')\n",
    "        line_count = 0\n",
    "        for row in csv_reader:\n",
    "            _description={row[0]:row[1]}\n",
    "            description_list.update(_description)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This function fills the severityDictionary with the data in symptom_severity\n",
    "def getSeverityDict():\n",
    "    global severityDictionary\n",
    "    with open('MasterData/symptom_severity.csv') as csv_file:\n",
    "\n",
    "        csv_reader = csv.reader(csv_file, delimiter=',')\n",
    "        line_count = 0\n",
    "        try:\n",
    "            for row in csv_reader:\n",
    "                _diction={row[0]:int(row[1])}\n",
    "                severityDictionary.update(_diction)\n",
    "        except:\n",
    "            pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This adds the precautions to precautionDictionary. This is a dict. of <Disease, Precaution[]>.\n",
    "def getprecautionDict():\n",
    "    global precautionDictionary\n",
    "    with open('MasterData/symptom_precaution.csv') as csv_file:\n",
    "\n",
    "        csv_reader = csv.reader(csv_file, delimiter=',')\n",
    "        line_count = 0\n",
    "        for row in csv_reader:\n",
    "            _prec={row[0]:[row[1],row[2],row[3],row[4]]}\n",
    "            precautionDictionary.update(_prec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Gets the patient name to greet.\n",
    "def getInfo():\n",
    "    print(\"-----------------------------------HealthCare ChatBot-----------------------------------\")\n",
    "    print(\"\\nYour Name? \\t\\t\\t\\t\",end=\"->\")\n",
    "    name=input(\"\")\n",
    "    print(\"Hello, \",name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_pattern(dis_list,inp):\n",
    "    pred_list=[]\n",
    "    inp=inp.replace(' ','_')\n",
    "    patt = f\"{inp}\"\n",
    "    regexp = re.compile(patt)\n",
    "    pred_list=[item for item in dis_list if regexp.search(item)] # returns the symptom if the input is present in the symptoms list.\n",
    "    if(len(pred_list)>0):\n",
    "        return 1,pred_list\n",
    "    else:\n",
    "        return 0,[]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Entrena el modelo, luego agarra el diccionario de sintoma y mapea el indice del sintoma al sintoma. Luego crea un arregla de 0 y los cambia a 1 para los sintomas que tiene y hace la prediccion cone se arreglo de 0 y 1 con el modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sec_predict(symptoms_exp):\n",
    "    df = pd.read_csv('Data/Training.csv')\n",
    "    X = df.iloc[:, :-1]\n",
    "    y = df['prognosis']\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=20)\n",
    "    rf_clf = DecisionTreeClassifier()\n",
    "    rf_clf.fit(X_train, y_train)\n",
    "\n",
    "    symptoms_dict = {symptom: index for index, symptom in enumerate(X)}\n",
    "    input_vector = np.zeros(len(symptoms_dict))\n",
    "    for item in symptoms_exp:\n",
    "      input_vector[[symptoms_dict[item]]] = 1\n",
    "\n",
    "    return rf_clf.predict([input_vector])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "imprime la enfermedad que tiene"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_disease(node):\n",
    "    node = node[0]\n",
    "    val  = node.nonzero() \n",
    "    disease = le.inverse_transform(val[0])\n",
    "    return list(map(lambda x:x.strip(),list(disease)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tree_to_code(tree, feature_names):\n",
    "    tree_ = tree.tree_\n",
    "    help(tree_)\n",
    "    feature_name = [\n",
    "        feature_names[i] if i != _tree.TREE_UNDEFINED else \"undefined!\"\n",
    "        for i in tree_.feature\n",
    "    ]\n",
    "\n",
    "    chk_dis=\",\".join(feature_names).split(\",\")\n",
    "    symptoms_present = []\n",
    "\n",
    "    while True:\n",
    "\n",
    "        print(\"\\nEnter the symptom you are experiencing  \\t\\t\",end=\"->\")\n",
    "        disease_input = input(\"\")\n",
    "        conf,cnf_dis=check_pattern(chk_dis,disease_input) # in case we want to implement natural language processing, we have to change this function.\n",
    "        if conf==1: # if the input is present in the disease list.\n",
    "            print(\"searches related to input: \")\n",
    "            for num,it in enumerate(cnf_dis):\n",
    "                print(num,\")\",it)\n",
    "            if num!=0:\n",
    "                print(f\"Select the one you meant (0 - {num}):  \", end=\"\")\n",
    "                conf_inp = int(input(\"\"))\n",
    "            else:\n",
    "                conf_inp=0\n",
    "\n",
    "            disease_input=cnf_dis[conf_inp]\n",
    "            break\n",
    "            # print(\"Did you mean: \",cnf_dis,\"?(yes/no) :\",end=\"\")\n",
    "            # conf_inp = input(\"\")\n",
    "            # if(conf_inp==\"yes\"):\n",
    "            #     break\n",
    "        else:\n",
    "            print(\"Enter valid symptom.\")\n",
    "\n",
    "    while True:\n",
    "        try:\n",
    "            num_days=int(input(\"Okay. From how many days ? : \"))\n",
    "            break\n",
    "        except:\n",
    "            print(\"Enter valid input.\")\n",
    "            \n",
    "    def recurse(node, depth):\n",
    "        indent = \"  \" * depth\n",
    "        if tree_.feature[node] != _tree.TREE_UNDEFINED:\n",
    "            name = feature_name[node]\n",
    "            threshold = tree_.threshold[node]\n",
    "\n",
    "            if name == disease_input:\n",
    "                val = 1\n",
    "            else:\n",
    "                val = 0\n",
    "            if  val <= threshold:\n",
    "                recurse(tree_.children_left[node], depth + 1)\n",
    "            else:\n",
    "                symptoms_present.append(name)\n",
    "                recurse(tree_.children_right[node], depth + 1)\n",
    "        else:\n",
    "            present_disease = print_disease(tree_.value[node])\n",
    "            # print( \"You may have \" +  present_disease )\n",
    "            red_cols = reduced_data.columns \n",
    "            symptoms_given = red_cols[reduced_data.loc[present_disease].values[0].nonzero()]\n",
    "            # dis_list=list(symptoms_present)\n",
    "            # if len(dis_list)!=0:\n",
    "            #     print(\"symptoms present  \" + str(list(symptoms_present)))\n",
    "            # print(\"symptoms given \"  +  str(list(symptoms_given)) )\n",
    "            print(\"Are you experiencing any \")\n",
    "            symptoms_exp=[]\n",
    "            for syms in list(symptoms_given):\n",
    "                inp=\"\"\n",
    "                print(syms,\"? : \",end='')\n",
    "                while True:\n",
    "                    inp=input(\"\")\n",
    "                    if(inp==\"yes\" or inp==\"no\"):\n",
    "                        break\n",
    "                    else:\n",
    "                        print(\"provide proper answers i.e. (yes/no) : \",end=\"\")\n",
    "                if(inp==\"yes\"):\n",
    "                    symptoms_exp.append(syms)\n",
    "\n",
    "            second_prediction=sec_predict(symptoms_exp)\n",
    "            # print(second_prediction)\n",
    "            calc_condition(symptoms_exp,num_days)\n",
    "            if(present_disease[0]==second_prediction[0]):\n",
    "                print(\"You may have \", present_disease[0])\n",
    "                print(description_list[present_disease[0]])\n",
    "\n",
    "                #readn(f\"You may have {present_disease[0]}\")\n",
    "                #eadn(f\"{description_list[present_disease[0]]}\")\n",
    "\n",
    "            else:\n",
    "                print(\"You may have \", present_disease[0], \"or \", second_prediction[0])\n",
    "                print(description_list[present_disease[0]])\n",
    "                print(description_list[second_prediction[0]])\n",
    "\n",
    "            # print(description_list[present_disease[0]])\n",
    "            precution_list=precautionDictionary[present_disease[0]]\n",
    "            print(\"Take following measures : \")\n",
    "            for  i,j in enumerate(precution_list):\n",
    "                print(i+1,\")\",j)\n",
    "\n",
    "            # confidence_level = (1.0*len(symptoms_present))/len(symptoms_given)\n",
    "            # print(\"confidence level is \" + str(confidence_level))\n",
    "\n",
    "    recurse(0, 1)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on Tree object:\n",
      "\n",
      "class Tree(builtins.object)\n",
      " |  Array-based representation of a binary decision tree.\n",
      " |  \n",
      " |  The binary tree is represented as a number of parallel arrays. The i-th\n",
      " |  element of each array holds information about the node `i`. Node 0 is the\n",
      " |  tree's root. You can find a detailed description of all arrays in\n",
      " |  `_tree.pxd`. NOTE: Some of the arrays only apply to either leaves or split\n",
      " |  nodes, resp. In this case the values of nodes of the other type are\n",
      " |  arbitrary!\n",
      " |  \n",
      " |  Attributes\n",
      " |  ----------\n",
      " |  node_count : int\n",
      " |      The number of nodes (internal nodes + leaves) in the tree.\n",
      " |  \n",
      " |  capacity : int\n",
      " |      The current capacity (i.e., size) of the arrays, which is at least as\n",
      " |      great as `node_count`.\n",
      " |  \n",
      " |  max_depth : int\n",
      " |      The depth of the tree, i.e. the maximum depth of its leaves.\n",
      " |  \n",
      " |  children_left : array of int, shape [node_count]\n",
      " |      children_left[i] holds the node id of the left child of node i.\n",
      " |      For leaves, children_left[i] == TREE_LEAF. Otherwise,\n",
      " |      children_left[i] > i. This child handles the case where\n",
      " |      X[:, feature[i]] <= threshold[i].\n",
      " |  \n",
      " |  children_right : array of int, shape [node_count]\n",
      " |      children_right[i] holds the node id of the right child of node i.\n",
      " |      For leaves, children_right[i] == TREE_LEAF. Otherwise,\n",
      " |      children_right[i] > i. This child handles the case where\n",
      " |      X[:, feature[i]] > threshold[i].\n",
      " |  \n",
      " |  feature : array of int, shape [node_count]\n",
      " |      feature[i] holds the feature to split on, for the internal node i.\n",
      " |  \n",
      " |  threshold : array of double, shape [node_count]\n",
      " |      threshold[i] holds the threshold for the internal node i.\n",
      " |  \n",
      " |  value : array of double, shape [node_count, n_outputs, max_n_classes]\n",
      " |      Contains the constant prediction value of each node.\n",
      " |  \n",
      " |  impurity : array of double, shape [node_count]\n",
      " |      impurity[i] holds the impurity (i.e., the value of the splitting\n",
      " |      criterion) at node i.\n",
      " |  \n",
      " |  n_node_samples : array of int, shape [node_count]\n",
      " |      n_node_samples[i] holds the number of training samples reaching node i.\n",
      " |  \n",
      " |  weighted_n_node_samples : array of double, shape [node_count]\n",
      " |      weighted_n_node_samples[i] holds the weighted number of training samples\n",
      " |      reaching node i.\n",
      " |  \n",
      " |  Methods defined here:\n",
      " |  \n",
      " |  __getstate__(...)\n",
      " |      Getstate re-implementation, for pickling.\n",
      " |  \n",
      " |  __reduce__(...)\n",
      " |      Reduce re-implementation, for pickling.\n",
      " |  \n",
      " |  __setstate__(...)\n",
      " |      Setstate re-implementation, for unpickling.\n",
      " |  \n",
      " |  apply(...)\n",
      " |      Finds the terminal region (=leaf node) for each sample in X.\n",
      " |  \n",
      " |  compute_feature_importances(...)\n",
      " |      Computes the importance of each feature (aka variable).\n",
      " |  \n",
      " |  compute_node_depths(...)\n",
      " |      Compute the depth of each node in a tree.\n",
      " |      \n",
      " |      .. versionadded:: 1.3\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      depths : ndarray of shape (self.node_count,), dtype=np.int64\n",
      " |          The depth of each node in the tree.\n",
      " |  \n",
      " |  compute_partial_dependence(...)\n",
      " |      Partial dependence of the response on the ``target_feature`` set.\n",
      " |      \n",
      " |      For each sample in ``X`` a tree traversal is performed.\n",
      " |      Each traversal starts from the root with weight 1.0.\n",
      " |      \n",
      " |      At each non-leaf node that splits on a target feature, either\n",
      " |      the left child or the right child is visited based on the feature\n",
      " |      value of the current sample, and the weight is not modified.\n",
      " |      At each non-leaf node that splits on a complementary feature,\n",
      " |      both children are visited and the weight is multiplied by the fraction\n",
      " |      of training samples which went to each child.\n",
      " |      \n",
      " |      At each leaf, the value of the node is multiplied by the current\n",
      " |      weight (weights sum to 1 for all visited terminal nodes).\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      X : view on 2d ndarray, shape (n_samples, n_target_features)\n",
      " |          The grid points on which the partial dependence should be\n",
      " |          evaluated.\n",
      " |      target_features : view on 1d ndarray, shape (n_target_features)\n",
      " |          The set of target features for which the partial dependence\n",
      " |          should be evaluated.\n",
      " |      out : view on 1d ndarray, shape (n_samples)\n",
      " |          The value of the partial dependence function on each grid\n",
      " |          point.\n",
      " |  \n",
      " |  decision_path(...)\n",
      " |      Finds the decision path (=node) for each sample in X.\n",
      " |  \n",
      " |  predict(...)\n",
      " |      Predict target for X.\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Static methods defined here:\n",
      " |  \n",
      " |  __new__(*args, **kwargs) from builtins.type\n",
      " |      Create and return a new object.  See help(type) for accurate signature.\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Data descriptors defined here:\n",
      " |  \n",
      " |  capacity\n",
      " |  \n",
      " |  children_left\n",
      " |  \n",
      " |  children_right\n",
      " |  \n",
      " |  feature\n",
      " |  \n",
      " |  impurity\n",
      " |  \n",
      " |  max_depth\n",
      " |  \n",
      " |  max_n_classes\n",
      " |  \n",
      " |  missing_go_to_left\n",
      " |  \n",
      " |  n_classes\n",
      " |  \n",
      " |  n_features\n",
      " |  \n",
      " |  n_leaves\n",
      " |  \n",
      " |  n_node_samples\n",
      " |  \n",
      " |  n_outputs\n",
      " |  \n",
      " |  node_count\n",
      " |  \n",
      " |  threshold\n",
      " |  \n",
      " |  value\n",
      " |  \n",
      " |  weighted_n_node_samples\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Data and other attributes defined here:\n",
      " |  \n",
      " |  __pyx_vtable__ = <capsule object NULL>\n",
      "\n",
      "\n",
      "Enter the symptom you are experiencing  \t\t->"
     ]
    }
   ],
   "source": [
    "# These functions load the data from MasterData to the dictionaries declared above.\n",
    "#getSeverityDict()\n",
    "#getDescription()\n",
    "#getprecautionDict()\n",
    "\n",
    "# Gets the patient's name and greets it.\n",
    "#getInfo()\n",
    "\n",
    "\n",
    "tree_to_code(clf,cols)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "healthcare-chatbot",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.17"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
